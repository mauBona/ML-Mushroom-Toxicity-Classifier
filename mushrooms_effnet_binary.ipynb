{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Mushroom Toxicity Classifier (Keras + EfficientNetB0)\n\nThis notebook trains a binary image classifier to predict whether a mushroom is toxic (1) or edible (0) using transfer learning with EfficientNetB0.\n\nIt includes:\n\n- Automatic Kaggle download of a mushroom images dataset (MO-106, 94 species, ~27k images).\n- A species->toxicity mapping step to build a binary folder-of-folders dataset (edible/, toxic/).\n- A tf.data pipeline with AUTOTUNE for performance.\n- EfficientNetB0 feature extraction + fine-tuning.\n- Class weights and threshold tuning to reduce false edible on toxic images.\n- (Optional) a tiny scratch CNN baseline for comparison.\n\n> References\n\n> - EfficientNet transfer learning (Keras official example): https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n\n> - EfficientNetB0 API docs: https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0\n\n> - Kaggle MO-106 (94 species): https://www.kaggle.com/datasets/iftekhar08/mo-106\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# Optional: install/upgrade packages if needed\n# !pip install -U tensorflow scikit-learn kaggle\n\nimport os, glob, shutil, zipfile\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nprint('TensorFlow:', tf.__version__)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 1) Kaggle setup (one-time)\n\nThis notebook uses Kaggle CLI to download the dataset. You need an API token at `~/.kaggle/kaggle.json`.\n\nHow to obtain and place it:\n\n1. Go to https://www.kaggle.com/ -> Profile -> Account -> Create New API Token (downloads kaggle.json).\n\n2. Upload it to this runtime at `~/.kaggle/kaggle.json` and set permissions `0o600`.\n\nUncomment and run the cell below if you need to place the token programmatically.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# # PLACE YOUR KAGGLE TOKEN (paste the JSON content between triple quotes)\n# kaggle_token = '''\n# {\"username\":\"YOUR_NAME\",\"key\":\"YOUR_KEY\"}\n# '''\n# import os\n# os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n# with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n#     f.write(kaggle_token.strip())\n# os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 2) Download & unpack MO-106 (images) from Kaggle\n\nWe will download MO-106 (94 species, ~27k images) and unpack under `data/mo106_raw/`.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "DATA_DIR = 'data'\nRAW_DIR  = os.path.join(DATA_DIR, 'mo106_raw')\nos.makedirs(DATA_DIR, exist_ok=True)\nprint('DATA_DIR:', DATA_DIR)\n\n# Download (uncomment in a real runtime with Kaggle CLI available)\n# !pip -q install kaggle\n# !kaggle datasets download -d iftekhar08/mo-106 -p {DATA_DIR} -o\n\n# Unzip (if needed)\n# for z in glob.glob(os.path.join(DATA_DIR, '*.zip')):\n#     print('Unzipping:', z)\n#     with zipfile.ZipFile(z, 'r') as f:\n#         f.extractall(RAW_DIR)\n\nprint('Expect raw dataset under:', RAW_DIR)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 3) Build a binary dataset (edible vs toxic)\n\nMO-106 is organized by species. We need to map each species to edible or toxic and then copy images into two folders. Expected structure after this step:\n\n- data/mushrooms_binary/\n  - edible/\n  - toxic/\n\nImportant: MO-106 variants may include a CSV/metadata file with edibility. Prefer using the official metadata when present. The code below shows a fallback heuristic (looks for tokens like 'edible', 'toxic', 'poison' in folder names). If your copy includes a reliable CSV, load it and replace the heuristic mapping.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "BIN_DIR = os.path.join(DATA_DIR, 'mushrooms_binary')\nif os.path.exists(BIN_DIR):\n    shutil.rmtree(BIN_DIR)\nos.makedirs(os.path.join(BIN_DIR, 'edible'), exist_ok=True)\nos.makedirs(os.path.join(BIN_DIR, 'toxic'),  exist_ok=True)\n\nspecies_to_label = {}\nif os.path.isdir(RAW_DIR):\n    for species_dir in glob.glob(os.path.join(RAW_DIR, '*')):\n        if not os.path.isdir(species_dir):\n            continue\n        folder = os.path.basename(species_dir)\n        name   = folder.lower()\n        if ('toxic' in name) or ('poison' in name):\n            species_to_label[folder] = 'toxic'\n        elif 'edible' in name:\n            species_to_label[folder] = 'edible'\n        else:\n            species_to_label[folder] = 'unknown'\n\nprint('Species mapped:', len(species_to_label))\nstats = {'edible':0, 'toxic':0, 'skipped':0}\nfor species_dir in glob.glob(os.path.join(RAW_DIR, '*')):\n    if not os.path.isdir(species_dir):\n        continue\n    tag = species_to_label.get(os.path.basename(species_dir), 'unknown')\n    if tag not in ('edible','toxic'):\n        stats['skipped'] += 1\n        continue\n    target = os.path.join(BIN_DIR, tag)\n    for img in glob.glob(os.path.join(species_dir, '*')):\n        if img.lower().endswith(('.jpg','.jpeg','.png')):\n            shutil.copy(img, target)\n            stats[tag] += 1\n\nprint('Binary copy stats:', stats)\nprint('Binary root:', BIN_DIR)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 4) tf.data pipeline (with AUTOTUNE)\n\nWe build a train/validation split directly from the `edible/` and `toxic/` folders.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "IMG_SIZE   = (224, 224)\nBATCH_SIZE = 32\nAUTOTUNE   = tf.data.AUTOTUNE\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    BIN_DIR, validation_split=0.2, subset='training', seed=42,\n    label_mode='binary', image_size=IMG_SIZE, batch_size=BATCH_SIZE)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    BIN_DIR, validation_split=0.2, subset='validation', seed=42,\n    label_mode='binary', image_size=IMG_SIZE, batch_size=BATCH_SIZE)\n\nnormalize = layers.Rescaling(1./255)\naugment   = tf.keras.Sequential([\n    layers.RandomFlip('horizontal'),\n    layers.RandomRotation(0.05),\n    layers.RandomZoom(0.05),\n])\n\ndef prep(x, y, training=False):\n    x = normalize(x)\n    if training:\n        x = augment(x)\n    return x, y\n\ntrain_ds = train_ds.map(lambda x,y: prep(x,y,True), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\nval_ds   = val_ds.map(prep, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n\n# Compute simple class weights\ncounts = {'edible':0, 'toxic':0}\nfor _, y in train_ds.unbatch().take(20000):\n    counts['toxic' if int(y.numpy())==1 else 'edible'] += 1\n\ntotal = max(1, counts['edible'] + counts['toxic'])\nw_edible = total / (2.0 * max(1, counts['edible']))\nw_toxic  = total / (2.0 * max(1, counts['toxic']))\nclass_weights = {0: w_edible, 1: w_toxic}\nprint('Class counts:', counts)\nprint('Class weights:', class_weights)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 5) EfficientNetB0 (feature extraction -> fine-tuning)\n\nWe follow Keras' transfer learning pattern: freeze the base (ImageNet weights), train the head, then unfreeze top blocks and fine-tune with a smaller learning rate.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "from tensorflow.keras.applications import EfficientNetB0\n\nbase = EfficientNetB0(include_top=False, weights='imagenet', input_shape=IMG_SIZE+(3,))\nbase.trainable = False\n\ninputs = layers.Input(shape=IMG_SIZE+(3,))\nx = base(inputs, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.25)(x)\noutputs = layers.Dense(1, activation='sigmoid')(x)\nmodel = models.Model(inputs, outputs, name='mushroom_effnet_b0')\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n              loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory_fe = model.fit(train_ds, validation_data=val_ds, epochs=5, class_weight=class_weights)\n\nbase.trainable = True\nfor layer in base.layers[:-30]:\n    layer.trainable = False\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory_ft = model.fit(train_ds, validation_data=val_ds, epochs=5, class_weight=class_weights)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 6) Threshold tuning (prioritize toxic recall)\n\nWe sweep decision thresholds and pick one with high recall on the toxic class.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import numpy as np\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n\ny_true, y_prob = [], []\nfor xb, yb in val_ds:\n    y_true.append(yb.numpy().ravel())\n    y_prob.append(model.predict(xb, verbose=0).ravel())\ny_true = np.concatenate(y_true)\ny_prob = np.concatenate(y_prob)\n\ncands = np.linspace(0.30, 0.80, 21)\nrecords = []\nfor th in cands:\n    y_pred = (y_prob >= th).astype(int)\n    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n    cm = confusion_matrix(y_true, y_pred)\n    records.append((th, p, r, f1, cm))\n\nbest = sorted(records, key=lambda x: (x[2], x[1], x[3]))[-1]\nprint('Best threshold:', round(best[0],2))\nprint('Precision:', round(best[1],3), 'Recall:', round(best[2],3), 'F1:', round(best[3],3))\nprint('Confusion matrix:\n', best[4])\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 7) (Optional) Tiny CNN baseline (from scratch)\n\nA compact CNN to visualize the lift you get from transfer learning.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "def tiny_cnn(input_shape=IMG_SIZE+(3,)):\n    inputs = layers.Input(shape=input_shape)\n    x = layers.Conv2D(16, 3, padding='same', activation='relu')(inputs)\n    x = layers.MaxPooling2D()(x)\n    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n    x = layers.MaxPooling2D()(x)\n    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.25)(x)\n    outputs = layers.Dense(1, activation='sigmoid')(x)\n    return models.Model(inputs, outputs, name='tiny_cnn')\n\nbaseline = tiny_cnn()\nbaseline.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# baseline.fit(train_ds, validation_data=val_ds, epochs=6, class_weight=class_weights)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Appendix \u2014 What is EfficientNetB0 (in brief)?\n\nEfficientNetB0 is the baseline model in the EfficientNet family. It achieves a strong accuracy-efficiency trade-off by compound scaling of depth, width, and resolution. It uses MBConv blocks, depthwise separable convolutions, and squeeze-and-excitation modules.\n\n- Great for transfer learning on small/medium datasets.\n\n- Input size: 224x224x3.\n\n- Docs: https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0\n\n- Keras example: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n"}]}